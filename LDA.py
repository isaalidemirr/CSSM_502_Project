# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12fGOZUG7ANlq1dRY8KouLKPK2t7om7Nn
"""

#Installation of stop-words

!pip install stop-words

#Required packages

from nltk.tokenize import RegexpTokenizer
from stop_words import get_stop_words
from nltk.stem.porter import PorterStemmer
from gensim import corpora, models
import gensim

#Google Drive 

from google.colab import drive
drive.mount('/content/gdrive')

#Path to the document

filepath='/content/gdrive/My Drive/HDP & BDP/ALL.txt'
f = open(filepath)
doc = f.read()

tokenizer = RegexpTokenizer(r'\w+')

# create English stop words list
en_stop = get_stop_words('en')

# Create p_stemmer of class PorterStemmer
p_stemmer = PorterStemmer()

# compile sample documents into a list
doc_set = [doc]

# list for tokenized documents in loop
texts = []

# loop through document list
for i in doc_set:
    
    # clean and tokenize document string
    raw = i.lower()
    tokens = tokenizer.tokenize(raw)

    # remove stop words from tokens
    stopped_tokens = [i for i in tokens if not i in en_stop]
    
    # stem tokens
    stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]
    
    # add tokens to list
    texts.append(stemmed_tokens)

# turn our tokenized documents into a id <-> term dictionary
dictionary = corpora.Dictionary(texts)
    
# convert tokenized documents into a document-term matrix
corpus = [dictionary.doc2bow(text) for text in texts]

#LDA model
ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=20, id2word = dictionary, passes=20)

!pip install pyLDAvis==2.1.2
import pyLDAvis.gensim

# Visualize the topics
pyLDAvis.enable_notebook()
vis = pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)
vis

from wordcloud import WordCloud
import matplotlib.pyplot as plt

# Create a list of lists where each sublist contains the top 20 words for a topic
top_words = [[word for word, _ in ldamodel.show_topic(topic_id, topn=20)] for topic_id in range(ldamodel.num_topics)]

# Create a figure with subplots
fig, axes = plt.subplots(5, 4, figsize=(20, 20))
axes = axes.ravel()

# Create a word cloud for each topic and display it in a subplot
for i, ax in enumerate(axes):
    wordcloud = WordCloud(width=600, height=400, background_color="white").generate(" ".join(top_words[i]))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.set_title("Topic {}".format(i+1))
    ax.axis("off")

plt.show()

